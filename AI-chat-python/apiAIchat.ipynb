{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3gF7HeZBopA"
      },
      "source": [
        "Model page: https://huggingface.co/indonesian-nlp/gpt2\n",
        "\n",
        "âš ï¸ If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/indonesian-nlp/gpt2)\n",
        "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) ðŸ™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhieVPe9XUyB",
        "outputId": "1523212f-08e1-465b-b8ee-9540f545c05a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting Flask-CORS\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok, Flask-CORS\n",
            "Successfully installed Flask-CORS-6.0.1 pyngrok-7.2.11\n",
            "Flask app started in background.\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ngrok authentication token set.\n",
            " * Public URL for AI API (Ngrok): https://0913-34-125-81-73.ngrok-free.app\n",
            "Keep this cell running in Colab to keep the tunnel active.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install Flask Flask-CORS pyngrok requests numpy scikit-learn\n",
        "\n",
        "import requests\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import numpy as np\n",
        "import json\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "from threading import Thread\n",
        "\n",
        "# --- IMPORTANT: Replace with your actual Hugging Face API token ---\n",
        "# You can get one from huggingface.co/settings/tokens\n",
        "HF_TOKEN = \"<HF TOKEN HERE>\"  # Replace with your Hugging Face token\n",
        "\n",
        "# --- IMPORTANT: Replace with your actual ngrok Auth Token ---\n",
        "# You can get one from dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_AUTH_TOKEN = \"<NGROK AUTH TOKEN HERE>\"  # Replace with your ngrok auth token\n",
        "\n",
        "\n",
        "# --- Configuration for Hugging Face API ---\n",
        "API_URL = \"https://api-inference.huggingface.co/models/LazarusNLP/all-indo-e5-small-v4\"\n",
        "HEADERS = {\"Authorization\": f\"Bearer {HF_TOKEN}\"} # Use the HF_TOKEN defined above\n",
        "\n",
        "# --- Sentence Similarity Function ---\n",
        "def get_similarity_scores_from_api(source_sentence, candidate_sentences):\n",
        "    \"\"\"\n",
        "    Gets similarity scores between a source sentence and a list of candidate sentences\n",
        "    using the Hugging Face Inference API, adapted for the SentenceSimilarityPipeline.\n",
        "    \"\"\"\n",
        "    if not source_sentence or not candidate_sentences:\n",
        "        print(\"Source sentence or candidate sentences cannot be empty for similarity calculation.\")\n",
        "        return None\n",
        "\n",
        "    payload = {\n",
        "        \"inputs\": {\n",
        "            \"source_sentence\": source_sentence,\n",
        "            \"sentences\": candidate_sentences\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"\\n--- Debugging get_similarity_scores_from_api ---\")\n",
        "    print(f\"API URL: {API_URL}\")\n",
        "    print(f\"Payload (JSON): {json.dumps(payload, indent=2)}\")\n",
        "\n",
        "    try:\n",
        "        response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
        "        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "\n",
        "        print(f\"Response Status Code: {response.status_code}\")\n",
        "        print(f\"Response Content: {response.text}\")\n",
        "\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching similarity scores: {e}\")\n",
        "        if response is not None:\n",
        "            print(f\"Response Status Code (on error): {response.status_code}\")\n",
        "            print(f\"Response Content (on error): {response.text}\")\n",
        "        return None\n",
        "\n",
        "# --- Recommendation Function ---\n",
        "def recommend_products(user_query, product_database, top_n=3):\n",
        "    \"\"\"\n",
        "    Recommends products based on user input by directly using the API's\n",
        "    sentence similarity calculation.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's description of their ideal product.\n",
        "        product_database (list of dict): A list of product dictionaries.\n",
        "                                         Each dict should have 'name' and 'description' or 'search_vector' (if not null).\n",
        "        top_n (int): The number of top recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        list of dict: A list of recommended products, ranked by similarity score,\n",
        "                      including their score.\n",
        "    \"\"\"\n",
        "    if not product_database:\n",
        "        print(\"Product database is empty. Cannot make recommendations.\")\n",
        "        return []\n",
        "\n",
        "    # Prepare candidate sentences: prioritize search_vector, then description, then name\n",
        "    candidate_sentences = []\n",
        "    for product in product_database:\n",
        "        if product.get('search_vector') and product['search_vector'] != \"null\": # Assuming \"null\" as string if it's not a real null\n",
        "            candidate_sentences.append(product['search_vector'])\n",
        "        elif product.get('description'):\n",
        "            candidate_sentences.append(product['description'])\n",
        "        else: # Fallback to name if description is also missing\n",
        "            candidate_sentences.append(product['name'])\n",
        "\n",
        "\n",
        "    # Get similarity scores for the user query against all product descriptions/vectors\n",
        "    similarity_scores = get_similarity_scores_from_api(user_query, candidate_sentences)\n",
        "\n",
        "    if similarity_scores is None:\n",
        "        print(\"Failed to get similarity scores for recommendations.\")\n",
        "        return []\n",
        "\n",
        "    similarity_scores = np.array(similarity_scores)\n",
        "\n",
        "    # Rank and retrieve top recommendations\n",
        "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
        "\n",
        "    recommendations = []\n",
        "    for i in range(min(top_n, len(ranked_indices))):\n",
        "        product_index = ranked_indices[i]\n",
        "        recommended_product = product_database[product_index].copy()\n",
        "        recommended_product['similarity_score'] = float(similarity_scores[product_index]) # Convert numpy float to Python float\n",
        "        recommendations.append(recommended_product)\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# --- Flask App Setup ---\n",
        "app = Flask(__name__)\n",
        "CORS(app) # Enable CORS for all routes\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"AI Product Recommender API is running!\"\n",
        "\n",
        "@app.route('/recommend', methods=['POST'])\n",
        "def get_recommendations():\n",
        "    data = request.get_json()\n",
        "    user_query = data.get('userQuery')\n",
        "    products = data.get('products') # This will be the list of all products from React\n",
        "\n",
        "    if not user_query or not products:\n",
        "        return jsonify({\"error\": \"Missing userQuery or products data\"}), 400\n",
        "\n",
        "    print(f\"Received user query: {user_query}\")\n",
        "    print(f\"Received {len(products)} products for recommendation.\")\n",
        "\n",
        "    recommended = recommend_products(user_query, products, top_n=3)\n",
        "\n",
        "    return jsonify({\"recommendations\": recommended}), 200\n",
        "\n",
        "# To run Flask in a non-blocking way in Colab with ngrok\n",
        "def run_flask():\n",
        "    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Start Flask in a separate thread\n",
        "flask_thread = Thread(target=run_flask)\n",
        "flask_thread.daemon = True\n",
        "flask_thread.start()\n",
        "\n",
        "print(\"Flask app started in background.\")\n",
        "\n",
        "# Now, try to establish ngrok tunnel\n",
        "try:\n",
        "    # Set the ngrok authentication token\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    print(\"ngrok authentication token set.\")\n",
        "\n",
        "    # Start ngrok tunnel\n",
        "    ngrok_url = ngrok.connect(5000).public_url\n",
        "    print(f\" * Public URL for AI API (Ngrok): {ngrok_url}\")\n",
        "    print(\"Keep this cell running in Colab to keep the tunnel active.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error starting ngrok: {e}\")\n",
        "    print(\"Please ensure your NGROK_AUTH_TOKEN is correct and try again.\")\n",
        "    print(\"If issues persist, try restarting the Colab runtime.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "gpu"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
